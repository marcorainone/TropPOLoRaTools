#!/usr/bin/env python3
# ===================================================================================
# Project:    TropPo 
#             v. 1.0 2020-03-01, ICTP Wireless Lab
# Programmer: Marco Rainone - ICTP Wireless Lab
# Specifications, revisions and verifications:   
#             Marco Zennaro, Ermanno Pietrosemoli, Marco Rainone - ICTP Wireless Lab
# ===================================================================================
#
# The project is released with Mit License
# https://opensource.org/licenses/MIT
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.
# ===================================================================================
#
# Info
# ----------------------------------------------------------------
# The program processes the csv file generated by the dist-dev-gtwttn.py program, 
# From the igra site, automatically downloads the troposonde archives with minimum distance.
# Igra site:
# https://www.ncdc.noaa.gov/data-access/weather-balloon/integrated-global-radiosonde-archive
# ftp://ftp.ncdc.noaa.gov/pub/data/igra
#
import os
import os.path
import getopt, sys
import datetime

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from staticmap import StaticMap, CircleMarker
import csv, json, sys
import geopy.distance
from array import *

import ftplib

# -------------------------------------------------------------------------
# igra log derived
# -------------------------------------------------------------------------

# return to ftp start directory
def ftpIgraRootDir(ftp):
    ftp_position = ftp.pwd()
    if ftp_position == '/':
        # sei gia' nella radice 
        return
    # count n. '/' in ftp_position
    count = ftp_position.count('/')
    path = ""
    for i in range(count):
        path += '../'
    ftp.cwd(path)

# return to ftp igra base dir
def ftpIgraBaseDir(ftp):
    ftpIgraRootDir(ftp)
    ftp.cwd('pub/data/igra')              # change into "pub/data/igra" directory

# return to ftp igra dir with derived data 
def ftpIgraDerivedDir(ftp):
    ftpIgraRootDir(ftp)
    ftp.cwd('pub/data/igra/derived/derived-por/')              

# get igra station list
def getIgraStationList(ftp, dirIgraLog):
    # goto ftp igra base dir
    ftpIgraBaseDir(ftp)
    
    # get radiosonde list
    # https://stackoverflow.com/questions/11573817/how-to-download-a-file-via-ftp-with-python-ftplib
    FileName = "igra2-station-list.txt"

    fpFileName = os.path.join(dirIgraLog, FileName)
    fileOut = open(fpFileName,'wb')
    op_completed = False
    try:
        print("... download: {} ...".format(FileName))
        ftp.retrbinary("RETR " + FileName ,fileOut.write)
        fileOut.close()
        op_completed = True
    except:
        print("Error ftp download file [{}]".format(FileName))
        fileOut.close()
        os.unlink(fpFileName)
    return(op_completed)
    
# get archive with Igra log
def getIgraDrvd(ftp, dirIgraLog, stationID):
    FileName = stationID + "-drvd.txt.zip"

    fpFileName = os.path.join(dirIgraLog, FileName)
    fileOut = open(fpFileName,'wb')
    op_completed = False
    try:
        print("... download: {} ...".format(FileName))
        ftp.retrbinary("RETR " + FileName ,fileOut.write)
        fileOut.close()
        op_completed = True
    except:
        print("Error ftp download file [{}]".format(FileName))
        fileOut.close()
        os.unlink(fpFileName)
    return(op_completed)

def igraDrvdExtract(dirIgraLog, stationID):
    # file name igra log archive
    fNameZipIgraLog = stationID + "-drvd" + ".txt.zip"
    fpZipIgraLog    = os.path.join(dirIgraLog, fNameZipIgraLog)     # full path zip

    # https://thispointer.com/python-how-to-unzip-a-file-extract-single-multiple-or-all-files-from-a-zip-archive/
    with ZipFile(fpZipIgraLog, 'r') as zipObj:
       # Extract all the contents of zip file in dirIgraLog
       zipObj.extractall(dirIgraLog)

def igraDrvdCreateIndex(dirIgraLog, stationID):
    keySearch = "#" + stationID             # esempio: #TSM00060760
    print(keySearch)
    
    # file name igra log archive, without extension
    fNameIgraLog = stationID + "-drvd"
    # file name radiosonda log index
    fNameIgraIndex = fNameIgraLog
    fNameIgraIndex += '.idx'
    # file name radiosonda log
    fNameIgraLog += '.txt'
    fpIgraLog = os.path.join(dirIgraLog, fNameIgraLog)
    print(fpIgraLog)
    fpIgraIndex = os.path.join(dirIgraLog, fNameIgraIndex)
    print(fpIgraIndex)

    fIdx = open(fpIgraIndex, 'w')               # open file index to write
    # write header
    lineIdx = csv_sep + "date" + csv_sep + "pos_header" + csv_sep + "pos_data"  + csv_sep + "n_rec" + '\n'
    fIdx.write(lineIdx)

    # read file log Igra
    numHeader = -1          # n. row header con data/ora specificata
    numRecords = 0          # n. records for each section    
    with open(fpIgraLog,'r') as rsLog:
        rsLog.seek(0, os.SEEK_END)  # go to the end of the file.
        eof = rsLog.tell()          # get the end of file location
        rsLog.seek(0, os.SEEK_SET)  # go to the beginning of the file.
        while(rsLog.tell() != eof):
            pos = rsLog.tell()                  # posizione file prima della lettura riga
            line = rsLog.readline().strip()
            if line.startswith(keySearch)==False:
                numRecords +=1
                continue
            # -------------- new header
            if numHeader >=0:
                # save numRecords and reinit value
                lineIdx = csv_sep + str(numRecords) + '\n'
                fIdx.write(lineIdx)
                numRecords = 0          # n. records for each section    
                
            numHeader += 1                  # incrementa n. row header con data/ora specificata

            # init line to write in index file
            lineIdx = str(numHeader)
            
            # add time acquisition
            # YEAR         14- 17  Integer
            # MONTH        19- 20  Integer
            # DAY          22- 23  Integer
            # HOUR         25- 26  Integer
            # date_acq = line[13:26]
            date_acq = line[13:17]          # year
            date_acq += '-' + line[18:20]   # month
            date_acq += '-' + line[21:23]   # day
            date_acq += ' ' + line[24:26]   # hour
            date_acq += ':00:00'
            # lineIdx += csv_sep + '\"' + date_acq + '\"'
            lineIdx += csv_sep + date_acq
            
            lineIdx += csv_sep + str(pos)

            posStartData = rsLog.tell()     # posizione file dopo della lettura riga
            lineIdx += csv_sep + str(posStartData)
            fIdx.write(lineIdx)

    # save last numRecords value
    lineIdx = csv_sep + str(numRecords) + '\n'
    fIdx.write(lineIdx)
    rsLog.close()
    fIdx.close()
    # ------------------ end igraDrvdCreateIndex

# ---------------------------------------------------------------
# config
#
PathBaseDir = os.getcwd()               # current working directory of the process
access_rights = 0o777                   # define the access rights file/folder
csv_sep = ';'                           # char separator for csv

# -------------------------------------------------------------------------
#
# get full path file or directory
def get_full_path(file_folder_name):
    return (os.path.abspath(file_folder_name))

# check if the full path is file
def is_directory(full_path):
    # os.path.exists checks whether a file or directory exists:
    ris = os.path.exists(full_path)
    if ris:
        # os.path.isdir checks whether it's a directory
        return (os.path.isdir(full_path))
    return False            # the path is not directory

# check if the full path is file
def is_file_name(full_path):
    # os.path.exists checks whether a file or directory exists:
    ris = os.path.exists(full_path)
    if ris:
        # os.path.isdir checks whether it's a directory
        return (not os.path.isdir(full_path))
    return False            # the path is not filename

def get_dir_name(full_path):
    dirname = os.path.dirname(full_path)    # os independent
    return dirname

# return the file name without path
def get_file_name(full_path):
    basename = os.path.basename(full_path)  # os independent
    base = basename.split('.')[0]
    return base

# return the extension of file
def get_file_ext(full_path):
    basename = os.path.basename(full_path)  # os independent
    ext = '.'.join(basename.split('.')[1:])
    if ext == '.':
        return ""
    return ext

def str2bool(v):
    return v.lower() in ("yes", "true", "t", "1")

def printHlpOptions():
    print('{} -i <log TTN events> -o <out dir>'.format(sys.argv[0]))

def printHlpFull():
    print('{} -i <log TTN events> -o <out dir>'.format(sys.argv[0]))
    print('Example:')
    print('{} -i rfsee_drivetest_unit_4.csv -o \"./outdir\"'.format(sys.argv[0]))
    print('Read rfsee_drivetest_unit_4.csv.'.format(sys.argv[0]))
    print('Store csv result file in ./output directory')

# -------------------------------------------------------------------------
# Get command-line arguments

# initialize variables
inpTTNEventsLog = ''
outDirCsv = ''
minDist = 20
flCaseGtwId = True

try:
    opts, args = getopt.getopt(
            sys.argv[1:],
            'i:o:',
            ["inp=","out="])
except getopt.GetoptError:
    printHlpFull()              # print full help
    sys.exit(2)

nArg = 0
for opt, arg in opts:
    if opt == '-h':
        printHlpFull()              # print full help
        sys.exit()
    elif opt in ("-i", "--inp"):
        inpTTNEventsLog = arg
        # print('TTN Mapper Log file: {}'.format(inpTTNEventsLog))
        nArg = nArg + 1
    elif opt in ("-o", "--out"):
        outDirCsv = arg
        # print('Output directory csv result: {}'.format(outDirCsv))
        nArg = nArg + 1

if nArg < 2:
    printHlpFull()              # print full help
    sys.exit()

# ---------------------------------------------------------------
# full path inpTTNMapperLog
fpTTNEventsLog = os.path.join(PathBaseDir, inpTTNEventsLog)

# get filename of output file
outCsv = 'rsl-' + get_file_name(inpTTNEventsLog) + '.csv'
# full path output dir
if not os.path.exists(outDirCsv):
    os.mkdir(outDirCsv, access_rights)
fpOutDir = get_full_path(outDirCsv)     # full path output dir

outDirRadioSonda = fpOutDir

# full path output file
fpOutCsv = os.path.join(fpOutDir, outCsv)

# file name of radiosonde list
LstFile = "igra2-station-list.txt"
fpLstFile = os.path.join(outDirRadioSonda, LstFile)

# -------------------------------------------------------------------------
# read list of files
#
# with ftplib.FTP("ftp://ftp.ncdc.noaa.gov/pub/data/igra/data/data-por/") as ftp:
nFiles = 0

# connect via ftp to igra
try:
    ftp = ftplib.FTP("ftp.ncdc.noaa.gov")
    ftp.login()
except:
    print("Error to connect Igra via ftp")
    sys.exit(2)

# goto ftp igra base dir
ftpIgraBaseDir(ftp)

# get radiosonde list
# https://stackoverflow.com/questions/11573817/how-to-download-a-file-via-ftp-with-python-ftplib
# get radiosonde list
if getIgraStationList(ftp, outDirRadioSonda) == False:
    print("Error download file list: {}".format(LstFile))
    sys.exit(2)

# Close the connection unilaterally
ftp.close()

# create pandas dataframe with list of radiosonde
## ------------------------------
## Variable   Columns   Type
## ID            1-11   Character
## LATITUDE     13-20   Real
## LONGITUDE    22-30   Real
## ELEVATION    32-37   Real
## STATE        39-40   Character
## NAME         42-71   Character
## FSTYEAR      73-76   Integer
## LSTYEAR      78-81   Integer
## NOBS         83-88   Integer
## ------------------------------

colIgra2Names = [
    "ICAONAT"   ,   # Character
    "NETCODE"   ,
    "IDCODE"    ,
    "IGRA2_ID"  ,   # Character
    "LATITUDE"  ,   # Real
    "LONGITUDE" ,   # Real
    "ELEVATION" ,   # Real
    "STATE"     ,   # Character
    "NAME"      ,   # Character
    "FSTYEAR"   ,   # Integer
    "LSTYEAR"   ,   # Integer
    "NOBS"      ,   # Integer
]

colIgra2StationList = [
    [ 0, 2],    # ICAONAT   : Character (Icao National Codes)
    [ 2, 3],    # NETCODE   : Character (Network Code: 
                #    I      : ICAO id (last 4 char IGRA2ID), 
                #    M      : WMO id number (last 5 char IGRA2ID),
                #    V      : Vol.Obs.id (last 5 to 6 char IGRA2ID)
                #    W      : WBAN id (last 5 char IGRA2ID)
                #    X      : Special id ("UA" with 6 alpha chr)
    [ 3,11],    # IDCODE    : Integer
    [ 0,11],    # IGRA2_ID  : Character
    [12,20],    # LATITUDE  : Real
    [21,30],    # LONGITUDE : Real
    [31,37],    # ELEVATION : Real
    [38,40],    # STATE     : Character
    [41,71],    # NAME      : Character
    [72,76],    # FSTYEAR   : Integer
    [77,81],    # LSTYEAR   : Integer
    [82,88]     # NOBS      : Integer
]

# https://www.programcreek.com/python/example/101362/pandas.read_fwf
igraStation = pd.read_fwf(fpLstFile, names=colIgra2Names, header=None, colspecs=colIgra2StationList)
# igraStation.to_csv('igra2station.csv', header=True, index=True, sep=csv_sep) 
igraStation.to_csv('igra2station.csv', header=True, index=False, sep=csv_sep) 

# filter elements in list:

# get actual year
now = datetime.datetime.now()
act_year = int(now.strftime("%Y"))      # now.strftime("%Y-%m-%d %H:%M:%S")
# filter list: remove lines with LSTYEAR less than act_year
igraStation.drop(igraStation.loc[igraStation['LSTYEAR']<act_year].index, inplace=True)

# filter list: remove lines with coordinates for mobile radiosonde (see igra2-list-format.txt):
# LATITUDE   is the latitude of the station (in decimal degrees, mobile = -98.8888).
# LONGITUDE  is the longitude of the station (in decimal degrees, mobile = -998.8888).
# ELEVATION  is the elevation of the station (in meters, missing = -999.9, mobile = -998.8).
igraStation.drop(igraStation.loc[igraStation['LONGITUDE'] == -998.8888].index, inplace=True)

# reindex
igraStation.reset_index(drop=True, inplace=True)

# save for debug
igraStation.to_csv('igra2-2020.csv', header=True, index=False, sep=csv_sep) 
# completata la lista di tutte le stazioni che hanno dati del 2020

# -------------------------------------------------------------------------
# leggi il csv di nome fpTTNEventsLog
# column_names = ['time','distance','nodeaddr','lat','lon','gwaddr','gtw_lat','gtw_lon']
data = pd.read_csv(fpTTNEventsLog, skipinitialspace = True, sep = csv_sep)
print(data)

# add new columns: rs_id, rs_lat, rs_lon, rs_distance, . Initialize with nan
data['rs_id'] = ''
data['rs_lat'] = np.NaN
data['rs_lon'] = np.NaN 
data['rs_distance'] = np.NaN 

# distance: set all values integer 
data['rs_distance'] = data['distance'].apply(np.int64)
# all coordinates with 4 decimals:
# see: https://www.geeksforgeeks.org/python-pandas-dataframe-round/
data = data.round({'rs_lat':4, 'rs_lon':4})

# https://www.geeksforgeeks.org/different-ways-to-iterate-over-rows-in-pandas-dataframe/
# iterate through each row data   
for i1 in data.index:
    print("row index: {}...".format(i1))
    # calculate median point of tw o coordinates
    mlat = (data['lat'][i1] + data['gtw_lat'][i1]) / 2.0
    mlon = (data['lon'][i1] + data['gtw_lon'][i1]) / 2.0
    coords_1 = (mlat, mlon)
    # initialize the last_distance to a dummy value, greather than expected
    last_distance = 400000.0                    # 400000km
    ## print(coords_1)
    for i2 in igraStation.index:
        coords_2 = (igraStation['LATITUDE'][i2], igraStation['LONGITUDE'][i2])
        distance=geopy.distance.geodesic(coords_1, coords_2).km
        
        # set flag checking value of rs_id is not set (cell has np.NaN)
        if last_distance > distance:
            # set new values in row
            data.at[i1, 'rs_id']        = igraStation.at[i2, 'IGRA2_ID']
            data.at[i1, 'rs_lat']       = igraStation.at[i2, 'LATITUDE']
            data.at[i1, 'rs_lon']       = igraStation.at[i2, 'LONGITUDE'] 
            data.at[i1, 'rs_distance']  = int(distance)
            last_distance = distance

radiosonde = data.rs_id.unique()

print("N. radiosonde identificate: {}".format(len(radiosonde)))
print(radiosonde)

# ---------------------------------------------------------------
# save the new csv with radiosonda info
data.to_csv(fpOutCsv, header=True, index=True, sep=csv_sep) 

if len(radiosonde) == 0:
    # exit.
    sys.exit()
    
# ---------------------------------------------------------------

# reconnect via ftp to igra
try:
    ftp = ftplib.FTP("ftp.ncdc.noaa.gov")
    ftp.login()
except:
    print("Error to connect Igra via ftp")
    sys.exit(2)

# goto ftp igra base dir
ftpIgraBaseDir(ftp)

# open ftp directory with radiosonda last data:
print(ftp.pwd())
ftpIgraRootDir(ftp)
print(ftp.pwd())

# return to ftp igra dir with derived data 
ftpIgraDerivedDir(ftp)
print(ftp.pwd())
print("ftp://ftp.ncdc.noaa.gov/pub/data/igra/derived/derived-por")

# get the radiosonoda files
nFiles = 0
for idRadioSonda in radiosonde:
    # 'l' (last):
    FileName = idRadioSonda + "-drvd.txt.zip"
    fpFileName = os.path.join(fpOutDir, FileName)
    fileOut = open(fpFileName,'wb')
    try:
        print("... download: {} ...".format(FileName))
        ftp.retrbinary("RETR " + FileName ,fileOut.write)
        fileOut.close()
        nFiles+=1
    except:
        print("Error download file: {}".format(FileName))
        fileOut.close()
        os.unlink(fpFileName)
        continue

print("Number of radiosonda files downloaded: {}".format(nFiles))
    
